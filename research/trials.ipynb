{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NgLaam\\Desktop\\chatbot\\medical-chatbot\\medical-chatbot\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone as PineconeStore\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = '8d7fd4ae-327c-4cd5-abbe-0c2d4769e37e'\n",
    "PINECONE_API_HOST = 'https://medical-chatbot-beutxtz.svc.gcp-starter.pinecone.io'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập biến môi trường cho Pinecone API key\n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract PDF data\n",
    "data_path = 'dataset/'\n",
    "\n",
    "def load_pdf(data_path):\n",
    "    loader = DirectoryLoader(data_path,\n",
    "                        glob = '*.pdf',\n",
    "                        loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents\n",
    "\n",
    "extract_data = load_pdf(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of my chunk is  7020\n"
     ]
    }
   ],
   "source": [
    "#Create text chunks\n",
    "def text_split(extract_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extract_data)\n",
    "\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(extract_data)\n",
    "print('Length of my chunk is ', len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query = embeddings.embed_query('Good morning')\n",
    "print('Length', len(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name =\"medical-chatbot\"\n",
    "\n",
    "#Creating Embeddings for each of the text chunks and storing \n",
    "docsearch = PineconeStore.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [Document(page_content='body, including the muscles, heart, nerves, and digestivesystem. Beriberi literally means “I can’t, I can’t” in Sing-halese, which reflects the crippling effect it has on itsvictims. It is common in parts of southeast Asia, wherewhite rice is the main food. In the United States, beriberiis primarily seen in people with chronic alcoholism .\\nDescription\\nBeriberi puzzled medical experts for years as it rav-'), Document(page_content='namely C. argentinense ,C. butyricum , and C. baratii ,b u t'), Document(page_content='Introduction .................................................... ix\\nAdvisory Board .............................................. xi\\nContributors ................................................. xiii\\nEntries\\nVolume 1: A-B .............................................. 1\\nVolume 2: C-F .......................................... 625\\nVolume 3: G-M ....................................... 1375\\nVolume 4: N-S ........................................ 2307')]\n"
     ]
    }
   ],
   "source": [
    "#Load index if we already have index\n",
    "docsearch = PineconeStore.from_existing_index(index_name, embeddings)\n",
    "\n",
    "query = 'Tôi là ai'\n",
    "\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "print('Result', docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])\n",
    "chain_type_kwargs={'prompt': PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model='model/llama-2-7b-chat.ggmlv3.q4_0.bin',\n",
    "                  model_type='llama',\n",
    "                  config={'max_new_tokens': 512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever = docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NgLaam\\Desktop\\chatbot\\medical-chatbot\\medical-chatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response : The amount of phlegm brought up during a cough can vary consid-erably from person to person. It is not possible to say exactly how muchphlegm someone with chronic bronchitis will cough up without knowingthe individual.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(f'Input Prompt:')\n",
    "    result=qa({'query': user_input})\n",
    "    print('Response :', result['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
